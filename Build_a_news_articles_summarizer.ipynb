{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQVIcL2LWULJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53591ef5-9459-4e12-941e-87719a1d4127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-core 0.3.63 requires pydantic>=2.7.4, but you have pydantic 1.10.22 which is incompatible.\n",
            "gradio 5.31.0 requires pydantic<2.12,>=2.0, but you have pydantic 1.10.22 which is incompatible.\n",
            "google-genai 1.18.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.22 which is incompatible.\n",
            "albumentations 2.0.8 requires pydantic>=2.9.2, but you have pydantic 1.10.22 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.22 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain==0.0.208 openai==0.27.8 python-dotenv newspaper3k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDuYoCMhWW_x",
        "outputId": "595f1217-8f7c-46fd-9ae0-328bd022e8f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "!echo \"OPENAI_API_KEY='Insert API key'\" > .env\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install newspaper\n",
        "!pip install newspaper3k\n",
        "!pip install lxml[html_clean]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymsx6Bslm5Y6",
        "outputId": "cf1e8fcf-0c17-4d48-945d-6b338d7f8d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting newspaper\n",
            "  Using cached newspaper-0.1.0.7.tar.gz (176 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.11/dist-packages (0.2.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (4.13.4)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (11.2.1)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (6.0.2)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (1.3.0)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (5.4.0)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (3.9.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (2.32.3)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (6.0.11)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (5.3.0)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (2.9.0.post0)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (4.14.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (2025.4.26)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.11/dist-packages (from tldextract>=2.0.1->newspaper3k) (2.1.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.18.0)\n",
            "Requirement already satisfied: lxml[html_clean] in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Collecting lxml_html_clean (from lxml[html_clean])\n",
            "  Downloading lxml_html_clean-0.4.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Downloading lxml_html_clean-0.4.2-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: lxml_html_clean\n",
            "Successfully installed lxml_html_clean-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6rH09GpWyP_",
        "outputId": "769560b2-e9ba-4946-dac1-13744888732c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Meta claims its new AI supercomputer will set records\n",
            "Text: Meta (formerly Facebook) has unveiled an AI supercomputer that it claims will be the world’s fastest.\n",
            "\n",
            "The supercomputer is called the AI Research SuperCluster (RSC) and is yet to be fully complete. However, Meta’s researchers have already begun using it for training large natural language processing (NLP) and computer vision models.\n",
            "\n",
            "RSC is set to be fully built in mid-2022. Meta says that it will be the fastest in the world once complete and the aim is for it to be capable of training models with trillions of parameters.\n",
            "\n",
            "“We hope RSC will help us build entirely new AI systems that can, for example, power real-time voice translations to large groups of people, each speaking a different language, so they can seamlessly collaborate on a research project or play an AR game together,” wrote Meta in a blog post.\n",
            "\n",
            "“Ultimately, the work done with RSC will pave the way toward building technologies for the next major computing platform — the metaverse, where AI-driven applications and products will play an important role.”\n",
            "\n",
            "For production, Meta expects RSC will be 20x faster than Meta’s current V100-based clusters. RSC is also estimated to be 9x faster at running the NVIDIA Collective Communication Library (NCCL) and 3x faster at training large-scale NLP workflows.\n",
            "\n",
            "A model with tens of billions of parameters can finish training in three weeks compared with nine weeks prior to RSC.\n",
            "\n",
            "Meta says that its previous AI research infrastructure only leveraged open source and other publicly-available datasets. RSC was designed with the security and privacy controls in mind to allow Meta to use real-world examples from its production systems in production training.\n",
            "\n",
            "What this means in practice is that Meta can use RSC to advance research for vital tasks such as identifying harmful content on its platforms—using real data from them.\n",
            "\n",
            "“We believe this is the first time performance, reliability, security, and privacy have been tackled at such a scale,” says Meta.\n",
            "\n",
            "(Image Credit: Meta)\n",
            "\n",
            "Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo. The next events in the series will be held in Santa Clara on 11-12 May 2022, Amsterdam on 20-21 September 2022, and London on 1-2 December 2022.\n",
            "\n",
            "Explore other upcoming enterprise technology events and webinars powered by TechForge here.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from newspaper import Article\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
        "}\n",
        "\n",
        "article_urls = \"https://www.artificialintelligence-news.com/2022/01/25/meta-claims-new-ai-supercomputer-will-set-records/\"\n",
        "\n",
        "session = requests.Session()\n",
        "\n",
        "try:\n",
        "    response = session.get(article_urls, headers=headers, timeout=10)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        article = Article(article_urls)\n",
        "        article.download()\n",
        "        article.parse()\n",
        "\n",
        "        print(f\"Title: {article.title}\")\n",
        "        print(f\"Text: {article.text}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Failed to fetch article at {article_urls}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error occurred while fetching article at {article_urls}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-neGI_O-WyH5"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import (\n",
        "    HumanMessage\n",
        ")\n",
        "\n",
        "# we get the article data from the scraping part\n",
        "article_title = article.title\n",
        "article_text = article.text\n",
        "\n",
        "# prepare template for prompt\n",
        "template = \"\"\"You are a very good assistant that summarizes online articles.\n",
        "\n",
        "Here's the article you want to summarize.\n",
        "\n",
        "==================\n",
        "Title: {article_title}\n",
        "\n",
        "{article_text}\n",
        "==================\n",
        "\n",
        "Write a summary of the previous article.\n",
        "\"\"\"\n",
        "\n",
        "prompt = template.format(article_title=article.title, article_text=article.text)\n",
        "\n",
        "messages = [HumanMessage(content=prompt)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYRzjToAXDUe"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# load the model\n",
        "chat = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVMxNufYXMek",
        "outputId": "2df918d3-29db-4baa-a590-bc9add729dca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta (formerly Facebook) has announced the development of the AI Research SuperCluster (RSC), which it claims will be the world's fastest AI supercomputer once completed in mid-2022. The RSC is designed to train large-scale natural language processing and computer vision models, with the capability to handle models with trillions of parameters. Meta aims to use the RSC for advanced AI applications, such as real-time voice translations for large groups and enhancing the metaverse with AI-driven technologies. The RSC is expected to be significantly faster than Meta's current systems, improving training times and incorporating enhanced security and privacy features to utilize real-world data from Meta's platforms safely. This development is part of Meta's broader strategy to advance AI research and application.\n"
          ]
        }
      ],
      "source": [
        "# generate summary\n",
        "summary = chat(messages)\n",
        "print(summary.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3LoDUVTXNJz",
        "outputId": "dbbcc58b-c49b-4210-d40c-1353bfdbc6c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Meta (formerly Facebook) has announced the development of a new AI supercomputer named the AI Research SuperCluster (RSC).\n",
            "- The RSC is not yet complete but is expected to be the world's fastest supercomputer by mid-2022.\n",
            "- Meta's researchers are already using RSC to train large-scale natural language processing (NLP) and computer vision models.\n",
            "- The supercomputer aims to support the training of models with trillions of parameters, enhancing capabilities such as real-time voice translations for large, multilingual groups.\n",
            "- RSC will significantly speed up AI model training, being 20x faster than Meta’s current systems and reducing training time for complex models from nine weeks to three weeks.\n",
            "- The design of RSC incorporates advanced security and privacy controls, enabling the use of real-world data from Meta's production systems for training purposes.\n",
            "- This infrastructure improvement will assist in tasks like identifying harmful content on Meta's platforms more effectively.\n",
            "- Meta highlights that the RSC represents a major step in performance, reliability, security, and privacy at scale.\n",
            "- The development of RSC is part of Meta's broader vision for the metaverse, where AI-driven applications will be crucial.\n",
            "- Related events include the AI & Big Data Expo, with upcoming dates in Santa Clara, Amsterdam, and London throughout 2022.\n"
          ]
        }
      ],
      "source": [
        "# prepare template for prompt\n",
        "template = \"\"\"You are an advanced AI assistant that summarizes online articles into bulleted lists.\n",
        "\n",
        "Here's the article you need to summarize.\n",
        "\n",
        "==================\n",
        "Title: {article_title}\n",
        "\n",
        "{article_text}\n",
        "==================\n",
        "\n",
        "Now, provide a summarized version of the article in a bulleted list format.\n",
        "\"\"\"\n",
        "\n",
        "# format prompt\n",
        "prompt = template.format(article_title=article.title, article_text=article.text)\n",
        "\n",
        "# generate summary\n",
        "summary = chat([HumanMessage(content=prompt)])\n",
        "print(summary.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPwrM1PWXtBr",
        "outputId": "5d953b73-aa9d-4845-da38-fc6f7a0abd54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Meta (anciennement Facebook) a dévoilé un superordinateur IA, le AI Research SuperCluster (RSC), prétendu être le plus rapide au monde une fois achevé.\n",
            "- Le RSC, qui n'est pas encore totalement complet, est déjà utilisé par les chercheurs de Meta pour entraîner de grands modèles de traitement du langage naturel (NLP) et de vision par ordinateur.\n",
            "- La construction complète du RSC est prévue pour mi-2022. Il devrait être capable de former des modèles avec des trillions de paramètres.\n",
            "- Meta envisage que le RSC permettra de créer de nouveaux systèmes IA pour des applications telles que les traductions vocales en temps réel pour de grands groupes de personnes parlant différentes langues.\n",
            "- Le RSC devrait être 20 fois plus rapide que les clusters actuels de Meta basés sur V100, 9 fois plus rapide pour exécuter la bibliothèque de communication collective NVIDIA (NCCL) et 3 fois plus rapide pour l'entraînement de workflows NLP à grande échelle.\n",
            "- Un modèle avec des dizaines de milliards de paramètres peut être formé en trois semaines avec le RSC, contre neuf semaines auparavant.\n",
            "- Le RSC a été conçu avec des contrôles de sécurité et de confidentialité, permettant à Meta d'utiliser des exemples réels de ses systèmes de production pour l'entraînement.\n",
            "- Ce superordinateur aidera Meta à avancer dans la recherche pour des tâches essentielles telles que l'identification de contenus nuisibles sur ses plateformes.\n",
            "- Meta affirme que c'est la première fois que la performance, la fiabilité, la sécurité et la confidentialité sont abordées à une telle échelle.\n",
            "- Pour en savoir plus sur l'IA et les grandes données, des événements comme l'AI & Big Data Expo auront lieu à Santa Clara, Amsterdam et Londres en 2022.\n"
          ]
        }
      ],
      "source": [
        "# prepare template for prompt\n",
        "template = \"\"\"You are an advanced AI assistant that summarizes online articles into bulleted lists in French.\n",
        "\n",
        "Here's the article you need to summarize.\n",
        "\n",
        "==================\n",
        "Title: {article_title}\n",
        "\n",
        "{article_text}\n",
        "==================\n",
        "\n",
        "Now, provide a summarized version of the article in a bulleted list format, in French.\n",
        "\"\"\"\n",
        "\n",
        "# format prompt\n",
        "prompt = template.format(article_title=article.title, article_text=article.text)\n",
        "\n",
        "# generate summary\n",
        "summary = chat([HumanMessage(content=prompt)])\n",
        "print(summary.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrx20THKYkA4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}